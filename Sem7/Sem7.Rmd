---
title: "Seminar 6 + 7"
author: "\\newline Zhdankina Margarita, Kolesnikova Victoria, Romanov Sergey"
output: 
  pdf_document:
    latex_engine: xelatex
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
suppressPackageStartupMessages(library(coda))
suppressPackageStartupMessages(library(RColorBrewer))
suppressPackageStartupMessages(library(sna))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(network))
suppressPackageStartupMessages(library(foreign))
suppressPackageStartupMessages(library(intergraph))
suppressPackageStartupMessages(library(NetCluster))
suppressPackageStartupMessages(library(dendextend))
```


# Seminar 6

```{r include=FALSE}
load("advice_data_frame.Rdata")
load("friendship_data_frame.Rdata")
load("reports_to_data_frame.Rdata")
load("reports_to_data_frame.Rdata")
load("attributes.Rdata")

head(advice_data_frame)
head(friendship_data_frame)
head(reports_to_data_frame)
```

```{r include=FALSE}
#First, make an array of 3 the 3 data frames
krack <- list(advice_data_frame,
              friendship_data_frame,
              reports_to_data_frame)
## add names to objects in list
graphs <- c('advice','friendship','reports')
names(krack) <- graphs
## check on list
length(krack) #how many elements we have in our krack dataset


names(krack)

for (i in 1:length(krack)){ 
  krack[[i]] <- as.matrix(krack[[i]])
}

for(i in 1:3){
  krack[[i]] <- subset(krack[[i]],
                       (krack[[i]][,3] > 0 ))
}

dim(krack[[1]]) 
head(krack[[1]])
names(attributes)
```

```{r include=FALSE}
attributes

for (i in 1:3){
  krack[[i]] <- network(krack[[i]],
                        matrix.type = 'edgelist',
                        vertex.attr = list(attributes[,1], attributes[,2],
                                           attributes[,3], attributes[,4]),
                        vertex.attrnames = list("AGE","TENURE","LEVEL","DEPT"))
}
advice <- krack$advice
friendship <- krack$friendship
reports <- krack$reports
```

```{r include=FALSE}
#Check networks
advice
friendship
reports
```

```{r include=FALSE}
#Let's take a look at these data.
#First, we create a set of coordinates to run the plot in.
#Detailed explanation of what we do here is provided in the answers to the third #seminar.
n<-network.size(advice)
v1<-sample((0:(n-1))/n) #create a vector of random numbers
v2<-sample(v1)
x <- n/(2 * pi) * sin(2 * pi * v1)
y <- n/(2 * pi) * cos(2 * pi * v2)
mycoord <- cbind(x,y)
```

```{r include=FALSE}
#Plot networks:
par(mar=c(0,0,1,0))
par(mfrow=c(1,3))
plot(advice, edge.col='azure4', vertex.col='darkorange',
     vertex.border='azure4',vertex.cex=2,coord=mycoord,
     main ='Advice')
plot(friendship, edge.col='azure4', vertex.col='darkorange',
     vertex.border='azure4',vertex.cex=2, coord=mycoord,
     main ='Friendship')
plot(reports, edge.col='azure4', vertex.col='darkorange',
     vertex.border='azure4',vertex.cex=2, coord=mycoord,
     main='Direct Reports')
```


## Assignment task 1

```{r include=FALSE}
library('igraph')
library('intergraph')
library('knitr')
```


*For the networks we’ve obtained, please calculate the following:*

*1. Dyad census*

*2. At least three types of centrality*

*3. Triad census*

*4. Transitivity*

*Having performed the calculations, please compare your results for each network and make appropriate inferences.*

```{r}
advice.graph <- asIgraph(advice)
friendship.graph <- asIgraph(friendship)
reports.graph <- asIgraph(reports)
```

DYADS

```{r}
d<-sapply(list(advice.graph,friendship.graph,reports.graph),dyad.census)
dyads <- data.frame(d)
colnames(dyads) <- c("advice", 'friendship', 'reports')
kable(dyads, label="Dyad Census")
```

CENTRALITY

```{r}
centralityA <- data.frame(row.names   = V(advice.graph),
                         degree      = degree(advice.graph),
                         betweenness = betweenness(advice.graph),
                         eigenvector = evcent(advice.graph)$vector)

centralityF <- centralityA[order(as.numeric(row.names(centralityA))),]

centralityF <- data.frame(row.names   = V(friendship.graph),
                          degree      = degree(friendship.graph),
                          betweenness = betweenness(friendship.graph),
                          eigenvector = evcent(friendship.graph)$vector)

centralityF <- centralityF[order(as.numeric(row.names(centralityF))),]

centralityR <- data.frame(row.names   = V(reports.graph),
                          degree      = degree(reports.graph),
                          betweenness = betweenness(reports.graph),
                          eigenvector = evcent(reports.graph)$vector)

centralityR <- centralityR[order(as.numeric(row.names(centralityR))),]
```

TRIADS

```{r}
types <-c('003','012','102','021D','021U','021C','111D','111U','030T','030C','201','120D','120U','120C', '210', '300')
t<-sapply(list(advice.graph,friendship.graph,reports.graph),triad_census)
triads <- data.frame(t)
rownames(triads) <- types
kable(triads, label="Triad Census")
```

TRANSITIVITY

```{r}
tr <-sapply(list(advice.graph,friendship.graph,reports.graph),transitivity)
transitivities <- data.frame(tr)
rownames(transitivities) <- c("advice", 'friendship', 'reports')


kable(dyads, label="Dyad Census")
kable(triads, label="Triad Census")
kable(transitivities, label="Transitivities")
```

From those computations we can observe that advice is the most connected network is the advice net, and the least is report net. Added to that, we can see that report net consist only of asymmetrical and null ties, which is logical, because it is hard to imagine co-workers who write reports and subordinate to each other.

With regard to friendship net, we can see that 56 people call someone a friend, but it was not mutual, sometimes it happens. But 23 ties between workers might be called friendship relations. The advice dyad and triad census provides some info that there is only 65 null ties and only 74 003 triads, which gives us a clue about well-developed "advice" culture in the net. We can also derive some logical conclusions form the absence of some triad types. For example, there is no 030C triads in friendship net: it is barely possible that three people can form a closed triad group. 

We have already mentioned that reports net does not have any mutual ties, but it also should be noted that the 021D triads are absent. It shows that there is no such supervisor in the organization who has two workers with the report obligation.
 
 
```{r}
kable(centralityA, row.names=T, label="Advice Centrality")
kable(centralityF, row.names=T, label="Friendship Centrality")
kable(centralityR, row.names=T, label="Reports Centrality")
```


Comparing centralities we can conclude pretty much the same things: reports net is the least connected net. Eigen vector centralities show that each net has the most "powerful" nodes: 18, 17, 14, respectively. However, if we compare particular nodes from the perspective of all nets, we can outline the 21th node, which has considerable figures in all three nets.

```{r include=FALSE}
detach(package:igraph)
```

```{r include=FALSE}
library(network)
library(sna)
```

```{r include=FALSE}
formal<-as.matrix(read.csv("formal.csv", header = TRUE, row.names=1))
roles<-read.csv("roles.csv", header=TRUE, row.names=1)
formalnet <- network(formal)
par(mar=c(0,0,2,0))
indeg <- degree(formalnet, cmode = 'indegree')
mycoord <- plot(formalnet, displaylabels=TRUE, edge.col='azure4',
                vertex.col="#E41A1C", vertex.border='azure4',
                vertex.cex = indeg + 1 , main ='Downton Abbey',
                label.cex=0.5, label.pos = 5)
```

```{r include=FALSE}
plot(formalnet)
```

```{r include=FALSE}
orRule <- symmetrize(formalnet, rule='weak') # "or" rule 
class(orRule) # symmetrize transformed the network into a matrix

orRule <- network(symmetrize(formalnet, rule='weak'), directed = FALSE) # 'or' rule
class(orRule) # network
andRule <- network(symmetrize(formalnet, rule='strong'), directed = FALSE) # 'and' rule
```

```{r include=FALSE}
warnings() 
```

```{r include=FALSE}
par(mar=c(1,1,2,1))
par(mfrow=c(1,3))
plot(formalnet, main = 'Original', coord=mycoord, vertex.cex =3,
     edge.col='azure4', vertex.col="#E41A1C", vertex.border='azure4',
     label=seq(1:20),label.pos=5,label.cex=.5,label.col='gray15')
plot(orRule, main = 'Or Rule', coord=mycoord, vertex.cex =3,
     edge.col='azure4', vertex.col="#377EB8", vertex.border='azure4',
     label=seq(1:20),label.pos=5,label.cex=.5,label.col='gray15')
plot(andRule, main = 'And Rule', coord=mycoord, vertex.cex =3,
     edge.col='azure4', vertex.col="#4DAF4A", vertex.border='azure4',
     label=seq(1:20),label.pos=5,label.cex=.5,label.col='gray15')
```

```{r include=FALSE}
snasymmformal <- orRule
aprioriformal<-blockmodel(snasymmformal, roles$commdetect,
                          block.content="density", mode="graph",
                          diag=FALSE)
```

```{r include=FALSE}
# We can build what is called a heatmap, showing the relationships between blocks in color
heatmap(aprioriformal[[4]])
```

```{r include=FALSE}
#Let's visualize the network with nodes colored by block. 
# These are our blocks.
aprioriformal[[1]]
aprioriformal[[2]]
aprioriformal[[3]]
aprioriformal[[4]]
```

```{r include=FALSE}
library('RColorBrewer')
suppressPackageStartupMessages('RColorBrewer')
par(mar=c(1,1,1,1),mfrow=c(2,3))
col5 <- brewer.pal(5, 'Set1')
cols <- ifelse(aprioriformal[[1]] == 1, col5[1],
               ifelse(aprioriformal[[1]] == 2, col5[2],
                      ifelse(aprioriformal[[1]] == 3, col5[3],
                             ifelse(aprioriformal[[1]] == 4, col5[4], col5[5]))))
par(mar=c(1,1,2,1),mfrow=c(1,1))
plot(snasymmformal, main = 'Apriori Block Model', coord=mycoord,
     vertex.cex =3, edge.col='azure4', vertex.col=cols,
     vertex.border='azure4', label=seq(1:20), label.pos=5,
     label.cex=.5, label.col='gray15')

```

```{r include=FALSE}
#Create an object of distances in the "OR rule," and turn it into a vector
distformal <- dist(snasymmformal, method="euclidian", diag=FALSE)
thick <- as.vector(distformal)
```

```{r include=FALSE}
#Now, let's visualize these distances as edge thickness
par(mar=c(0.5,0,2,0))
plot(snasymmformal, main = 'Euclidean Distances', coord=mycoord,
     vertex.cex =3, edge.col='azure4', vertex.col=col5[2],
     vertex.border='azure4', label=seq(1:20),label.pos=5,
     label.cex=.5,label.col='gray15', edge.lwd = thick*2)
```

```{r include=FALSE}
#Cluster analysis
formalclust <- hclust(distformal, method="complete")
```

```{r include=FALSE}
#And now, a blockmodel based on clustering:
exploratoryformal<-blockmodel(snasymmformal, formalclust, k=6,
                              block.content="density", mode="graph",
                              diag=FALSE)
```

```{r}
#Plot the two blockmodels one after another for comparison:
par(mar=c(0,0,2,0))
plot.blockmodel(aprioriformal)

plot.blockmodel(exploratoryformal)

heatmap(exploratoryformal[[4]], main ='Exploratory Blockmodel')
```

```{r}
plot(exploratoryformal, main = 'Apriori Block Model', coord=mycoord,
     vertex.cex =3, edge.col='azure4', vertex.col=cols,
     vertex.border='azure4', label=seq(1:20), label.pos=5,
     label.cex=.5, label.col='gray15')
```


## Assignment task 2

*1. Experiment with k. We’ve set it to 6, but would another number make more sense?*

*2. Which of the two blockmodels appear to be more accurate to you? Why?*


```{r}
exploratoryformal.01<-blockmodel(snasymmformal, formalclust, k=5,
                                 block.content="density", mode="graph",
                                 diag=FALSE)
```

Plot the two blockmodels one after another for comparison:

```{r}
par(mar=c(0,0,2,0))
plot.blockmodel(exploratoryformal.01)
```

```{r}
exploratoryformal.02<-blockmodel(snasymmformal, formalclust, k=7,
                              block.content="density", mode="graph",
                              diag=FALSE)
```

Plot the two blockmodels one after another for comparison:

```{r}
par(mar=c(0,0,2,0))
plot.blockmodel(exploratoryformal.02)
```

We have tried 5 and 7 clusters. From the picture of 5,6,and 7 we can outline that with 7 clusters we can separate two groups of nodes with 4 and 3 ties.

```{r include=FALSE}
par(mar = c(1,1,4,1), mfrow = c(1,2))
heatmap(aprioriformal[[4]], main ='Apriori Blockmodel')
heatmap(exploratoryformal[[4]], main ='Exploratory Blockmodel')
connectedformal<-formal[-20,-20] # operation on the matrix 
class(connectedformal)
```

```{r include=FALSE}
CONCOR <- function(mat, max.iter=1000, epsilon=1e-10){
  mat <- rbind(mat, t(mat)) # stack
  colN <- ncol(mat) # width
  X <- matrix(rep(0, times=colN*colN), nrow=colN, ncol=colN) 
  target.abs.value <- colN * colN - epsilon # convergence target 
  for (iter in 1:max.iter){
    for(i in 1:colN){
      for(j in i:colN){
        X[i,j]<-cor(mat[,i], mat[,j], method=c("pearson"))
      } # end for j
    } # end for i
    mat <- X+(t(X)-diag(diag((X))))
    if (sum(abs(mat)) > target.abs.value) { # test convergence
      #Finished before max.iter iterations
      return(mat) 
    } # end if
  } # end for iterations
  return(mat) # return matrix 
} # end function
```


```{r include=FALSE}
rownames(connectedformal) <- row.names(roles)[1:19]
colnames(connectedformal) <- row.names(roles)[1:19]
## connected formal
#Now, run the matrix through the CONCOR function and show the blockmodel:
CONCORFORMAL<-CONCOR(connectedformal)
# You can look at the matrix on your own; we commented it out to save space in the documen
## print(CONCORFORMAL)
heatmap(CONCORFORMAL)
```

```{r include=FALSE}
## part 1  -it's blocks from 14 to 19:
part1 <- connectedformal[14:19,14:19] 
colnames(part1) # Who are in this partition?
concor1 <- CONCOR(part1)
heatmap(concor1)
```

```{r include=FALSE}
part2 <- connectedformal[1:13,1:13] # isolate the first 13 nodes
# We commented the matrix out, but you can look at it on your own
##part2
concor2 <- CONCOR(part2) # Run through CONCOR 
heatmap(concor2) # Look at the result
```

```{r include=FALSE}
part3<-c(1,3,8,9,12,13) # isolate the needed nodes 
part3.1<-part2[part3,part3] # remove the isolates from partition 2 
colnames(part3.1) # Who is here?
```

```{r include=FALSE}
part3.2 <- part2[-part3,-part3] # Extract remaining nodes from part2 
concor3.2 <- CONCOR(part3.2) # Run it through CONCOR 
heatmap(concor3.2)
```

```{r include=FALSE}
colnames(part3.2[1:2,1:2]) # Names in the first subpart
```

```{r include=FALSE}
colnames(part3.2[3:7,3:7]) # Names in the second subpart
```

```{r include=FALSE}
part3.2.2 <- part3.2[3:7,3:7] # Create a partition
# Code below will choke RMarkdown, run it in CONSOLE ONLY (it's commented out here):
##concor3.2.2<-CONCOR(part3.2.2)
```

```{r include=FALSE}
# Set up an example matrix.
mat <- matrix(rbinom(25, 1, 0.5), nr = 5, nc = 5)
colnames(mat) <- c('A','B','C','D','E')
rownames(mat) <- c('A','B','C','D','E')
# Stack the matrix with its transpose
mat

t(mat)
#what if this was a symmetrical matrix? Would it work? -- think about it. :-)
```

## Assignment task 3

*Try not to get lost in all the partitions! Please list all the finite block-partitions that we have generated and the names of all people that ended up in every block*

```{r}
colnames(part1)
colnames(part2)
colnames(part3.1)
colnames(part3.2)
colnames(part3.2.2)
```

```{r}
colN <-sapply(list(part1,part2,part3.1,part3.2,part3.2.2 ),colnames)
colnames(part1)
df1<-data.frame(sort(colnames(part1)))
df2<-data.frame(sort(colnames(part2)))
df3<-data.frame(sort(colnames(part3.1)))
df4<-data.frame(sort(colnames(part3.2)))
df5<-data.frame(sort(colnames(part3.2.2)))
```

```{r}
colnames(df1)<-c('part1')
colnames(df2)<-c('part2')
colnames(df3)<-c('part3.1')
colnames(df4)<-c('part3.2')
colnames(df5)<-c('part3.2.2')
```

```{r}
kable(df1)
kable(df2)
kable(df3)
kable(df4)
kable(df5)
```


```{r include=FALSE}
#library(kableExtra)

#table.1985 %>%
#  kable_styling(full_width = F, position = "float_left")

#table.2015 %>%
#  kable_styling(full_width = F, position = "right")
```


```{r include=FALSE}
mat <- rbind(mat,t(mat))
# Then concor makes a square matrix of 0s of the same dimensions as mat's width
X <- matrix(rep(0, times=5*5), nrow=5, ncol=5)
X
```

```{r include=FALSE}
# Then for each cell in X it puts the correlation between the stack matrix's # columm of Xrow and the colum of Xcol
X[2,4]<-cor(mat[,2], mat[,4], method=c("pearson")) ##
X
```

```{r include=FALSE}
## cov(X,Y) = E[(X - MuX)*(Y - MuY)]
## and sd(X) = sqrt(E( X - MuX)
###
# The function works until it finishes filling the X matrix once for each cell in X
for(i in 1:5){ for(j in i:5){
  X[i,j]<-cor(mat[,i], mat[,j], method=c("pearson")) } # end for j
} # end for i X
```

```{r include=FALSE}
load('friend_df.Rdata')
load('m182_full_data_frame.Rdata')
load('social_df.Rdata')
load('task_df.Rdata')

# Check the data we have in the dataset:
head(m182_full_data_frame)
m182_full_nonzero_edges <- subset(m182_full_data_frame,
                                  (friend_tie > 0 | social_tie > 0 | task_tie > 0))
head( m182_full_nonzero_edges) 
m182_full_nonzero_edges
suppressPackageStartupMessages(library(igraph)) 
m182_full <- graph.data.frame(m182_full_nonzero_edges) 
summary(m182_full) #check the data
```

```{r include=FALSE}
m182_friend <- delete.edges(m182_full, E(m182_full)[E(m182_full)$friend_tie==0])
m182_social <- delete.edges(m182_full, E(m182_full)[E(m182_full)$social_tie==0])
m182_task <- delete.edges(m182_full, E(m182_full)[E(m182_full)$task_tie==0])
```


## Assignment task 4

*Why do we remove the zero edges from networks? We haven’t done it previously, why are we doing it now?*


Because previously we have not used nets to create edge attributes, and zero edges might provoke distortion in attribute figures, as missing values might do with classical data.
 
```{r include=FALSE}
task_adjacency<-get.adjacency(m182_task, attr='task_tie') # This is if we only want the tie (so it's 0 or 1) 
binary_task_adjacency<-get.adjacency(m182_task)
```

```{r include=FALSE}
task_adjacency<-as.matrix(task_adjacency) #generate the matrix out of a graph # Create a nx2n matrix of directed connections 
task_matrix<-rbind(task_adjacency,t(task_adjacency))
# Same for matrix of social connections:
social_adjacency<-get.adjacency(m182_social, attr='social_tie') 
binary_social_adjacency<-get.adjacency(m182_social) #this is for later 
social_adjacency<-as.matrix(social_adjacency) 
social_matrix<-rbind(social_adjacency,t(social_adjacency))
# Because we want to analyze social and task connections together, bind matrices:
task_social_matrix <-rbind(task_matrix,social_matrix)
dim(task_social_matrix)
```

```{r include=FALSE}
task_social_cors<-cor(task_social_matrix) # Correlate matrices
## task_social_cors #If you want to check the matrix, uncomment this line
```

```{r include=FALSE}
dissimilarity<-1-task_social_cors #subtract matrix values from 1 
task_social_dist<-as.dist(dissimilarity) #create a distance matrix
#You can check the matrix if you wish:
##task_social_dist
task_social_dist<-dist(t(task_social_matrix))
task_social_dist
library(NetCluster) # add the library to complete the clustering 
task_social_hclust <- hclust(task_social_dist) 
plot(task_social_hclust)
```

```{r include=FALSE}
cutree(task_social_hclust, k=2)
clustered_observed_cors = vector() # set it as a vector 
num_vertices = length(V(m182_task)) # get the length of the vector
```

```{r include=FALSE}
clustered_observed_cors<-clustConfigurations(num_vertices,task_social_hclust,task_social_cors)
clustered_observed_cors$correlations
```

```{r include=FALSE}
num_clusters = 4 # Test our number of clusters
clusters <- cutree(task_social_hclust, k = num_clusters) 
clusters
```

```{r include=FALSE}
cluster_cor_mat <- clusterCorr(task_social_cors,
                               clusters)
cluster_cor_mat
gcor(cluster_cor_mat, task_social_cors)
```

## Assignment task 5

*What rationale do you have for selecting the number of clusters / positions with the method above? Please rely on your knowledge of cluster analysis to answer this question.*

First of all, we can observe the scree plot and look for big changes in delta of the correlation coefficient. Also, in cluster analysis it is important to look at cluster stability(how often elements jump to another cluster with the increase of k), but we do not have the relevant info. 

```{r include=FALSE}
apriori = c(1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3)
deductive_cluster_cor_mat <- generate_cluster_cor_mat(task_social_cors, apriori)
gcor(deductive_cluster_cor_mat, task_social_cors)
```

```{r include=FALSE}
# Blockmodel on valued task data
task_valued_blockmodel <- blockmodel(task_adjacency, clusters)
# Blockmodel on binary task data binary_task_adjacency<-as.matrix(binary_task_adjacency) # turn graph to matrix first task_binary_blockmodel <- blockmodel(binary_task_adjacency, clusters)
# Blockmodel on valued social data
social_valued_blockmodel <- blockmodel(social_adjacency, clusters)
```

```{r include=FALSE}
#Blockmodel on binary social data
binary_social_adjacency<-as.matrix(binary_social_adjacency)
social_binary_blockmodel <- blockmodel(binary_social_adjacency, clusters)
```

```{r include=FALSE}
task_density <- graph.density(m182_task)
task_density
```

```{r include=FALSE}
social_mean <- mean(social_adjacency)
social_mean
```

```{r include=FALSE}
social_density <- graph.density(m182_social)
social_density
```

```{r include=FALSE}
col5 <- brewer.pal(5, 'Set1')
cols <- ifelse(aprioriformal[[1]] == 1, col5[1],
        ifelse(aprioriformal[[1]] == 2, col5[2],
        ifelse(aprioriformal[[1]] == 3, col5[3],
        ifelse(aprioriformal[[1]] == 4, col5[4], col5[5]))))
par(mar=c(1,1,2,1),mfrow=c(1,1))
plot(snasymmformal, main = 'Apriori Block Model', coord=mycoord,
     vertex.cex =3, edge.col='azure4', vertex.col=cols,
     vertex.border='azure4', label=seq(1:20), label.pos=5,
     label.cex=.5, label.col='gray15')
```


## Assignment task 6

*- Plot the resulting blockmodels in any way you wish and examine them visually. What is the story you get from viewing these clusters, and their within and between cluster densities on task and social interaction? What can you say about your network from this?*

```{r}
exploratoryadjacency<-blockmodel(task_adjacency, clusters, k=8,
                              block.content="density", mode="graph",
                              diag=FALSE)


plot.blockmodel(task_valued_blockmodel)
plot.blockmodel(social_valued_blockmodel)
plot.blockmodel(social_binary_blockmodel)

plot.blockmodel(exploratoryadjacency)
Answer: From those graphs we can observe that the task relation is barely related with the social relation. 
For example, the node number 16 is ill connected in social net, but helped almost every one, 
which could be seen from the task net. 
What is more, the most successful social nodes — 1 and 10 – have not a lot of ties in social net. We have could claimed the 
opposite relationship, if not the group of 2, 8, and 13, which are connected in both nets. 
```

*- We have learned several ways to blockmodel. 
Which method do you find the most intuitively appealing? Why?*
CONCOR method was new and interesting, but it is failing our console, so we prefer good old cluster analysis, as we have known it before and it was easy to apply

*- What did you learn from blockmodels about your data that you could not generate from previously learned techniques?* 

We have equipped ourselves with skills about how to divide nets and nets data into groups. Before we have studied how to calculate the probabilities for the formation of a new tie with ergm model, but now we also can detect subgroups in the net.


\newpage

# Seminar 7

```{r include=FALSE}
detach(package:NetCluster)
detach(package:sna)
detach(package:network)
suppressPackageStartupMessages(library(igraph))
```

```{r include=FALSE}
wd<-getwd()
```

```{r include=FALSE}
SWFile <- "/SouthernWomen/SouthernWomen.tsv"
```

```{r include=FALSE}
SWFilePath <- paste(wd, SWFile, sep = "")
```

```{r include=FALSE}
SWrawdata<-read.table(SWFilePath, sep = "\t", header = TRUE, row.names = 1)
SWrawdata
```

## Assignment task 1

*In your Seminar 7 folder, there is another file with data, HiTech. Create the code that will do the following:*

*- Create a directory that will consist of a working directory name and the HiTech folder name, so that it opens the HiTech folder.*

*- Create file paths to separate data files "GivesAdviceTo," "IsFriendOf," "ReportsTo," and "HiTechAtt.""*

```{r}
wd<-getwd()
```

```{r}
HTFile1 <- "/HiTech/HiTech - GivesAdviceTo.tsv"
HTFilePath1 <- paste(wd, HTFile1, sep = "")
GivesAdviceTo<-read.table(HTFilePath1, sep = "\t", header = TRUE, row.names = 1)
head(GivesAdviceTo)

HTFile2 <- "/HiTech/HiTech - IsFriendOf.tsv"
HTFilePath2 <- paste(wd, HTFile2, sep = "")
IsFriendOf<-read.table(HTFilePath2, sep = "\t", header = TRUE, row.names = 1)
head(IsFriendOf)

HTFile3 <- "/HiTech/HiTech - ReportsTo.tsv"
HTFilePath3 <- paste(wd, HTFile3, sep = "")
ReportsTo<-read.table(HTFilePath3, sep = "\t", header = TRUE, row.names = 1)
head(ReportsTo)

HTFile4 <- "/HiTech/HiTech - HiTechAtt.tsv"
HTFilePath4 <- paste(wd, HTFile4, sep = "")
HiTechAtt<-read.table(HTFilePath4, sep = "\t", header = TRUE, row.names = 1)
head(HiTechAtt)
```

## Assignment task 2

*Using the plotting function in igraph, improve my graph for the SouthernWomen data by changing at least three characteristics of the graph.*

```{r include=FALSE}
SWnet<-graph_from_incidence_matrix(SWrawdata)
# Of course, the first thing we do with our data is look at it, so
par(mar=c(0,0,0,0))
plot(SWnet)
```

```{r include=FALSE}
 V(SWnet)$type
 V(SWnet)$name
library(RColorBrewer)
colors<-brewer.pal(8, 'Accent') #select and load a palette
```

```{r include=FALSE}
V(SWnet)$color <- c(colors[1],colors[6])[V(SWnet)$type+1] 
V(SWnet)$shape <- c("square", "circle")[V(SWnet)$type+1] 
V(SWnet)$label.color<-c("black","white")[V(SWnet)$type+1]
V(SWnet)$label.cex<-c(0.5, 0.7)[V(SWnet)$type+1]
V(SWnet)$label.font=2
```

```{r include=FALSE}
V(SWnet)$indegree <- degree(SWnet, mode = "in") #calculate indegree
```

```{r include=FALSE}
V(SWnet)$size<-ifelse(V(SWnet)$type==TRUE,V(SWnet)$indegree*3,15)
```

```{r include=FALSE}
par(mar=c(0,0,0,0))
plot(SWnet)
```

```{r include=FALSE}
par(mar=c(0,0,0,0))
plot(SWnet, layout=layout.bipartite)
```

```{r include=FALSE}
V(SWnet)$shape='none'
V(SWnet)$label.color<-c("black",colors[6])[V(SWnet)$type+1]
V(SWnet)$label.cex<-ifelse(V(SWnet)$type==TRUE,0.25+V(SWnet)$indegree/10,0.5)
par(mar=c(0,0,0,0))
plot(SWnet, layout=layout.bipartite)
```

```{r}
V(SWnet)$shape='none'
V(SWnet)$label.color<-c("black",colors[6])[V(SWnet)$type+1]
V(SWnet)$label.cex<-ifelse(V(SWnet)$type==FALSE,0.25+V(SWnet)$indegree/10,0.25+V(SWnet)$indegree/10)
V(SWnet)$label.dist<-ifelse(V(SWnet)$type==TRUE,0,(V(SWnet)$label.degree=0))
V(SWnet)$label.family<-"Times"
V(SWnet)$label.font<-ifelse(V(SWnet)$type==TRUE,4,1)
par(mar=c(0,0,0,0))
LO <- layout_as_bipartite(SWnet)
plot(SWnet, layout=LO[,2:1])
```

```{r include=FALSE}
SWnet.sep<-bipartite.projection(SWnet)
```

```{r include=FALSE}
par(mar=c(0,0,0,0), mfrow=c(1,2))
plot(SWnet.sep$proj1)
plot(SWnet.sep$proj2)
```

## Assignment task 3

*Display the contents of the Women.only and Events.only matrices we created above.*

*- Explain what data in these matrices mean.*

*- What are the benefits and problems with separating incidence matrices and creating adjacency matrices out of them?*

```{r include=FALSE}
Women.only<-as.matrix(SWrawdata)%*%t(as.matrix(SWrawdata)) # Matrix of women only 
Events.only<-t(as.matrix(SWrawdata))%*%as.matrix(SWrawdata) # Matrix of events only
```

```{r}
head(Women.only)
head(Events.only)
```

The matrix with the data about women (Women.only) represents the information about the possibility that women were at the same parties. We can say that this matrix reflects the fact of co-presence at the events. The women can be perceived as nodes in the future network, and the events - as ties.

The matrix with the data about events (Events.only) contains information about the relationship of events to each other. It turns out that for this matrix, the ties will be the women who attended the events, and the events themselves are the nodes of the future network, based on this matrix.

Benefits of adjacency matrices:
By separating the matrices, we can take a closer look at the various indicators, in this case, the connection between the participants of events and the events themselves. For example, with the separation of matrices, both the connection between people and between events becomes more evident, as they are observed separately from each other.

Problems of adjacency matrices:
By separating information about people and events, it becomes difficult to tell exactly how and where event participants are likely to meet. Thus, it is possible to know that some people are connected (or that they were ontook part in the same events), but information about which events brought them together is missed. In the same way, information is lost for events. You can trace that they are somehow connected, but which people unite particular events by their presence at them remains questionable.


## Assignment task 4

*For the network SouthernWomen, please calculate the following network characteristics and briefly explain what they mean:*

*- Indegree, outdegree, total degree;*

*- Centrality: degree, betweenness, closeness, eigenvector, page rank; correlations between these measures.*

*- Transitivity.*


```{r}
degree <- data.frame(row.names = V(SWnet.sep$proj1)$name,
                    T_degree = degree(SWnet.sep$proj1, mode ="total"),
                    O_degree = degree(SWnet.sep$proj1, mode= "out"), 
                    I_degree = degree(SWnet.sep$proj1, mode= "in"))
                         
                         
kable(degree, row.names=T, label="Degrees")                         
```

As our network is made undirected all types of degree are equal to each other. Theresa is has the biggest degree centralites. 

```{r}
centralities <- data.frame(row.names = V(SWnet.sep$proj1)$name,
                         degree = degree(SWnet.sep$proj1),
                         betweenness = betweenness(SWnet.sep$proj1),
                         closeness =  closeness(SWnet.sep$proj1),
                         eigenvector = evcent(SWnet.sep$proj1)$vector,
                         page_rank = page_rank(SWnet.sep$proj1)$vector)
                         
                         
kable(centralities, row.names=T, label="Southern Women Centrality")                         
```

While Olivia and Flora are the highest in betweenness and closeness centralities, Therersa is leading in eigen and page rank figures.With regard to the least numbers, the belong to the same nodes but vise versa: Theresa is smallest in  betweenness and closeness, and Olivia and Flora are in eigen and page rank.

```{r}
cor(centralities)                       
```

Because degree, page_rank and eigen vector are computed without pathways they negatively correlate with betweenness and
closeness centrality. 

```{r}
transitivity(SWnet.sep$proj1)
```

As we can see, Southern Women Network is almost fully transitive. 

